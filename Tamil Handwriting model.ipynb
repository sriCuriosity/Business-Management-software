{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-02T06:54:53.302753Z",
     "iopub.status.busy": "2025-07-02T06:54:53.302341Z",
     "iopub.status.idle": "2025-07-02T06:54:53.308791Z",
     "shell.execute_reply": "2025-07-02T06:54:53.307598Z",
     "shell.execute_reply.started": "2025-07-02T06:54:53.302722Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import os\n",
    "import random\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "#import tensorflow_addons as tfa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-02T06:54:55.584062Z",
     "iopub.status.busy": "2025-07-02T06:54:55.583541Z",
     "iopub.status.idle": "2025-07-02T06:54:55.608502Z",
     "shell.execute_reply": "2025-07-02T06:54:55.607382Z",
     "shell.execute_reply.started": "2025-07-02T06:54:55.584023Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class TamilHandwritingRecognizer:\n",
    "    def __init__(self, img_height=64, img_width=256, max_length=32):\n",
    "        self.img_height = img_height\n",
    "        self.img_width = img_width\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        # Tamil character set (simplified - expand as needed)\n",
    "        self.tamil_chars = [\n",
    "            'அ', 'ஆ', 'இ', 'ஈ', 'உ', 'ஊ', 'எ', 'ஏ', 'ஐ', 'ஒ', 'ஓ', 'ஔ',\n",
    "            'க', 'ங', 'ச', 'ஞ', 'ட', 'ண', 'த', 'ந', 'ப', 'ம', 'ய', 'ர', 'ல', 'வ', 'ழ', 'ள', 'ற', 'ன',\n",
    "            'ா', 'ி', 'ீ', 'ு', 'ூ', 'ெ', 'ே', 'ை', 'ொ', 'ோ', 'ௌ', '்',\n",
    "            ' ', '<PAD>', '<START>', '<END>'\n",
    "        ]\n",
    "        \n",
    "        self.char_to_idx = {char: idx for idx, char in enumerate(self.tamil_chars)}\n",
    "        self.idx_to_char = {idx: char for idx, char in enumerate(self.tamil_chars)}\n",
    "        self.vocab_size = len(self.tamil_chars)\n",
    "        \n",
    "        self.model = None\n",
    "\n",
    "\n",
    "    def build_model(self):\n",
    "        \"\"\"Build CNN + LSTM model for handwriting recognition\"\"\"\n",
    "        \n",
    "        # Input layer\n",
    "        input_img = layers.Input(shape=(self.img_height, self.img_width, 1), name='image_input')\n",
    "        \n",
    "        # CNN Feature Extraction\n",
    "        x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
    "        x = layers.MaxPooling2D((2, 2))(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        \n",
    "        x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "        x = layers.MaxPooling2D((2, 2))(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        \n",
    "        x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "        x = layers.MaxPooling2D((2, 2))(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        \n",
    "        x = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
    "        x = layers.MaxPooling2D((2, 2))(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        \n",
    "        # Reshape for RNN\n",
    "        new_shape = ((self.img_width // 16), (self.img_height // 16) * 256)\n",
    "        x = layers.Reshape(target_shape=new_shape)(x)\n",
    "        x = layers.Dense(64, activation='relu')(x)\n",
    "        \n",
    "        # RNN layers\n",
    "        x = layers.Bidirectional(layers.LSTM(128, return_sequences=True, dropout=0.25))(x)\n",
    "        x = layers.Bidirectional(layers.LSTM(64, return_sequences=True, dropout=0.25))(x)\n",
    "        \n",
    "        # Output layer\n",
    "        output = layers.Dense(self.vocab_size, activation='softmax', name='output')(x)\n",
    "        \n",
    "        # Create model\n",
    "        self.model = models.Model(inputs=input_img, outputs=output)\n",
    "        \n",
    "        # Compile model\n",
    "        self.model.compile(\n",
    "            optimizer='adam',\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        \n",
    "        return self.model\n",
    "\n",
    "\n",
    "    def preprocess_image(self, image_path):\n",
    "        \"\"\"Preprocess image for model input\"\"\"\n",
    "        img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        # Resize image\n",
    "        img = cv2.resize(img, (self.img_width, self.img_height))\n",
    "        \n",
    "        # Normalize\n",
    "        img = img.astype(np.float32) / 255.0\n",
    "        \n",
    "        # Add channel dimension\n",
    "        img = np.expand_dims(img, axis=-1)\n",
    "        \n",
    "        return img\n",
    "\n",
    "\n",
    "    def encode_text(self, text):\n",
    "        \"\"\"Encode text to sequence of indices\"\"\"\n",
    "        encoded = [self.char_to_idx.get(char, self.char_to_idx['<PAD>']) for char in text]\n",
    "        encoded = pad_sequences([encoded], maxlen=self.max_length, padding='post')[0]\n",
    "        return to_categorical(encoded, num_classes=self.vocab_size)\n",
    "\n",
    "\n",
    "    def decode_prediction(self, prediction):\n",
    "        \"\"\"Decode model prediction to text\"\"\"\n",
    "        predicted_indices = np.argmax(prediction, axis=-1)\n",
    "        decoded_text = ''.join([self.idx_to_char[idx] for idx in predicted_indices])\n",
    "        \n",
    "        # Remove padding and special tokens\n",
    "        decoded_text = decoded_text.replace('<PAD>', '').replace('<START>', '').replace('<END>', '')\n",
    "        \n",
    "        return decoded_text.strip()\n",
    "\n",
    "\n",
    "    def train(self, train_images, train_labels, validation_split=0.2, epochs=50, batch_size=32):\n",
    "        \"\"\"Train the model\"\"\"\n",
    "        \n",
    "        # Split data\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            train_images, train_labels, test_size=validation_split, random_state=42\n",
    "        )\n",
    "        \n",
    "        # Callbacks\n",
    "        callbacks = [\n",
    "            tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True),\n",
    "            tf.keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=5),\n",
    "            tf.keras.callbacks.ModelCheckpoint('tamil_handwriting_best.h5', save_best_only=True)\n",
    "        ]\n",
    "        \n",
    "        # Train model\n",
    "        history = self.model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_val, y_val),\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            callbacks=callbacks,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        return history\n",
    "\n",
    "    def predict(self, image):\n",
    "        \"\"\"Predict text from image\"\"\"\n",
    "        if len(image.shape) == 3:\n",
    "            image = np.expand_dims(image, axis=0)\n",
    "        \n",
    "        prediction = self.model.predict(image)\n",
    "        decoded_text = self.decode_prediction(prediction[0])\n",
    "        \n",
    "        # Calculate confidence\n",
    "        confidence = np.mean(np.max(prediction[0], axis=-1))\n",
    "        \n",
    "        return decoded_text, confidence\n",
    "\n",
    "\n",
    "# Data preparation functions\n",
    "    def prepare_tamil_dataset(data_path):\n",
    "        labels_df = pd.read_csv(os.path.join(data_path, 'labels.csv'))\n",
    "    \n",
    "        images = []\n",
    "        labels = []\n",
    "    \n",
    "        recognizer = TamilHandwritingRecognizer()\n",
    "    \n",
    "        for _, row in labels_df.iterrows():\n",
    "            image_path = os.path.join(data_path, 'images', row['filename'])\n",
    "        \n",
    "            if os.path.exists(image_path):\n",
    "            # Preprocess image\n",
    "                img = recognizer.preprocess_image(image_path)\n",
    "                images.append(img)\n",
    "            \n",
    "            # Encode label\n",
    "                encoded_label = recognizer.encode_text(row['text'])\n",
    "                labels.append(encoded_label)\n",
    "    \n",
    "        return np.array(images), np.array(labels)\n",
    "\n",
    "\n",
    "\n",
    "    def augment_image(img):\n",
    "        \"\"\"Apply random augmentation: rotation, shift, zoom, brightness, flips\"\"\"\n",
    "        img = tf.image.random_brightness(img, max_delta=0.2)\n",
    "        img = tf.image.random_contrast(img, lower=0.8, upper=1.2)\n",
    "        img = tf.image.random_flip_left_right(img)\n",
    "        img = tf.image.random_flip_up_down(img)\n",
    "        # Random rotation\n",
    "        angle = random.uniform(-0.15, 0.15)  # radians\n",
    "        img_rotated = tf.image.rot90(img, k=int(angle / (tf.pi/2))) \n",
    "        return img\n",
    "\n",
    "    def evaluate_character_level(model, X, y_true, recognizer):\n",
    "        y_pred = model.predict(X)\n",
    "        y_pred_indices = np.argmax(y_pred, axis=-1)\n",
    "        y_true_indices = np.argmax(y_true, axis=-1)\n",
    "        acc = accuracy_score(y_true_indices, y_pred_indices)\n",
    "        cm = confusion_matrix(y_true_indices, y_pred_indices)\n",
    "        print(f\"Character-level accuracy: {acc:.4f}\")\n",
    "        return acc, cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-02T06:55:01.402876Z",
     "iopub.status.busy": "2025-07-02T06:55:01.402400Z",
     "iopub.status.idle": "2025-07-02T06:55:01.415973Z",
     "shell.execute_reply": "2025-07-02T06:55:01.414878Z",
     "shell.execute_reply.started": "2025-07-02T06:55:01.402838Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def prepare_tamil_dataset_kaggle(data_path, recognizer, augment=False):\n",
    "    train_csv = os.path.join(data_path, \"train.csv\")\n",
    "    img_dir = os.path.join(data_path, \"Train-Kaggle\", \"Train-Kaggle\")\n",
    "    df = pd.read_csv(train_csv)\n",
    "\n",
    "    images = []\n",
    "    labels = []\n",
    "    skipped = 0\n",
    "    for idx, row in df.iterrows():\n",
    "        img_path = os.path.join(img_dir, row['ImageId'])\n",
    "        label_idx = row['Class Label']\n",
    "        # Data cleaning: skip if file missing or label out of range\n",
    "        if not os.path.exists(img_path):\n",
    "            skipped += 1\n",
    "            continue\n",
    "        if not (0 <= label_idx < len(recognizer.tamil_chars)):\n",
    "            skipped += 1\n",
    "            continue\n",
    "        try:\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "            if img is None:\n",
    "                skipped += 1\n",
    "                continue\n",
    "            img = cv2.resize(img, (recognizer.img_width, recognizer.img_height))\n",
    "            img = img.astype(np.float32) / 255.0\n",
    "            img = np.expand_dims(img, axis=-1)\n",
    "            if augment:\n",
    "                img = augment_image(img)\n",
    "            images.append(img)\n",
    "                # One-hot encode label\n",
    "            label = recognizer.char_to_idx[recognizer.tamil_chars[label_idx]]\n",
    "            label = tf.keras.utils.to_categorical(label, num_classes=recognizer.vocab_size)\n",
    "            labels.append(label)\n",
    "        except Exception:\n",
    "            skipped += 1\n",
    "            continue\n",
    "    print(f\"Loaded {len(images)} samples, skipped {skipped} due to errors.\")\n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-02T07:01:31.803322Z",
     "iopub.status.busy": "2025-07-02T07:01:31.802416Z",
     "iopub.status.idle": "2025-07-02T07:01:33.798326Z",
     "shell.execute_reply": "2025-07-02T07:01:33.797092Z",
     "shell.execute_reply.started": "2025-07-02T07:01:31.803284Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Summary:\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " image_input (InputLayer)    [(None, 64, 256, 1)]      0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 64, 256, 32)       320       \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 32, 128, 32)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 32, 128, 32)      128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 32, 128, 64)       18496     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 16, 64, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 16, 64, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 16, 64, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 8, 32, 128)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 8, 32, 128)       512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 8, 32, 256)        295168    \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 4, 16, 256)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 4, 16, 256)       1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " reshape_1 (Reshape)         (None, 16, 1024)          0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 16, 64)            65600     \n",
      "                                                                 \n",
      " bidirectional_2 (Bidirectio  (None, 16, 256)          197632    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " bidirectional_3 (Bidirectio  (None, 16, 128)          164352    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " output (Dense)              (None, 16, 46)            5934      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 823,278\n",
      "Trainable params: 822,318\n",
      "Non-trainable params: 960\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'ImageId'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'ImageId'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m     data_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/kaggle/input/tamil-hwcr\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     12\u001b[0m     recognizer \u001b[38;5;241m=\u001b[39m TamilHandwritingRecognizer( img_height\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, img_width\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m     X_train, y_train \u001b[38;5;241m=\u001b[39m \u001b[43mprepare_tamil_dataset_kaggle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecognizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Now you can train as before:\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# history = recognizer.train(X_train, y_train, epochs=100)\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;66;03m# https://www.kaggle.com/datasets/tamil-handwriting-recognition\u001b[39;00m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;66;03m# Or create custom dataset\u001b[39;00m\n\u001b[1;32m     22\u001b[0m     data_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath/to/tamil_handwriting_dataset\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "Cell \u001b[0;32mIn[7], line 10\u001b[0m, in \u001b[0;36mprepare_tamil_dataset_kaggle\u001b[0;34m(data_path, recognizer, augment)\u001b[0m\n\u001b[1;32m      8\u001b[0m skipped \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, row \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m---> 10\u001b[0m     img_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(img_dir, \u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mImageId\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     11\u001b[0m     label_idx \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClass Label\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m# Data cleaning: skip if file missing or label out of range\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/series.py:981\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    978\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m--> 981\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_hashable(key):\n\u001b[1;32m    984\u001b[0m     \u001b[38;5;66;03m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[1;32m    985\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    986\u001b[0m         \u001b[38;5;66;03m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/series.py:1089\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1086\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[1;32m   1088\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1089\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1090\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39m_get_values_for_loc(\u001b[38;5;28mself\u001b[39m, loc, label)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/indexes/base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3804\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3805\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3806\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'ImageId'"
     ]
    }
   ],
   "source": [
    "# Training script\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize model\n",
    "    recognizer = TamilHandwritingRecognizer()\n",
    "    model = recognizer.build_model()\n",
    "    \n",
    "    print(\"Model Summary:\")\n",
    "    model.summary()\n",
    "    \n",
    "    # Example usage in your notebook:\n",
    "    data_path = \"/kaggle/input/tamil-hwcr\"\n",
    "    recognizer = TamilHandwritingRecognizer( img_height=64, img_width=256, max_length=32)\n",
    "    X_train, y_train = prepare_tamil_dataset_kaggle(data_path, recognizer, augment=True)\n",
    "# Now you can train as before:\n",
    "# history = recognizer.train(X_train, y_train, epochs=100)\n",
    "\n",
    "    # Load and prepare data\n",
    "    # Download Tamil handwriting dataset from:\n",
    "    # https://www.kaggle.com/datasets/tamil-handwriting-recognition\n",
    "    # Or create custom dataset\n",
    "    \n",
    "    data_path = \"path/to/tamil_handwriting_dataset\"\n",
    "    # X_train, y_train = prepare_tamil_dataset(data_path)\n",
    "    \n",
    "    # Train model\n",
    "    # history = recognizer.train(X_train, y_train, epochs=100)\n",
    "    \n",
    "    # Save model\n",
    "    # model.save('tamil_handwriting_model.h5')\n",
    "    \n",
    "    print(\"Tamil Handwriting Recognition Model Ready!\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 6350438,
     "sourceId": 58786,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30528,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
