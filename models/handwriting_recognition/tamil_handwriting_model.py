{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers, models\nimport numpy as np\nimport cv2\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.utils import to_categorical\n\nclass TamilHandwritingRecognizer:\n    def __init__(self, img_height=64, img_width=256, max_length=32):\n        self.img_height = img_height\n        self.img_width = img_width\n        self.max_length = max_length\n        \n        # Tamil character set (simplified - expand as needed)\n        self.tamil_chars = [\n            'அ', 'ஆ', 'இ', 'ஈ', 'உ', 'ஊ', 'எ', 'ஏ', 'ஐ', 'ஒ', 'ஓ', 'ஔ',\n            'க', 'ங', 'ச', 'ஞ', 'ட', 'ண', 'த', 'ந', 'ப', 'ம', 'ய', 'ர', 'ல', 'வ', 'ழ', 'ள', 'ற', 'ன',\n            'ா', 'ி', 'ீ', 'ு', 'ூ', 'ெ', 'ே', 'ை', 'ொ', 'ோ', 'ௌ', '்',\n            ' ', '<PAD>', '<START>', '<END>'\n        ]\n        \n        self.char_to_idx = {char: idx for idx, char in enumerate(self.tamil_chars)}\n        self.idx_to_char = {idx: char for idx, char in enumerate(self.tamil_chars)}\n        self.vocab_size = len(self.tamil_chars)\n        \n        self.model = None\n        \n    def build_model(self):\n        \"\"\"Build CNN + LSTM model for handwriting recognition\"\"\"\n        \n        # Input layer\n        input_img = layers.Input(shape=(self.img_height, self.img_width, 1), name='image_input')\n        \n        # CNN Feature Extraction\n        x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n        x = layers.MaxPooling2D((2, 2))(x)\n        x = layers.BatchNormalization()(x)\n        \n        x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n        x = layers.MaxPooling2D((2, 2))(x)\n        x = layers.BatchNormalization()(x)\n        \n        x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n        x = layers.MaxPooling2D((2, 2))(x)\n        x = layers.BatchNormalization()(x)\n        \n        x = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n        x = layers.MaxPooling2D((2, 2))(x)\n        x = layers.BatchNormalization()(x)\n        \n        # Reshape for RNN\n        new_shape = ((self.img_width // 16), (self.img_height // 16) * 256)\n        x = layers.Reshape(target_shape=new_shape)(x)\n        x = layers.Dense(64, activation='relu')(x)\n        \n        # RNN layers\n        x = layers.Bidirectional(layers.LSTM(128, return_sequences=True, dropout=0.25))(x)\n        x = layers.Bidirectional(layers.LSTM(64, return_sequences=True, dropout=0.25))(x)\n        \n        # Output layer\n        output = layers.Dense(self.vocab_size, activation='softmax', name='output')(x)\n        \n        # Create model\n        self.model = models.Model(inputs=input_img, outputs=output)\n        \n        # Compile model\n        self.model.compile(\n            optimizer='adam',\n            loss='categorical_crossentropy',\n            metrics=['accuracy']\n        )\n        \n        return self.model\n    \n    def preprocess_image(self, image_path):\n        \"\"\"Preprocess image for model input\"\"\"\n        img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n        \n        # Resize image\n        img = cv2.resize(img, (self.img_width, self.img_height))\n        \n        # Normalize\n        img = img.astype(np.float32) / 255.0\n        \n        # Add channel dimension\n        img = np.expand_dims(img, axis=-1)\n        \n        return img\n    \n    def encode_text(self, text):\n        \"\"\"Encode text to sequence of indices\"\"\"\n        encoded = [self.char_to_idx.get(char, self.char_to_idx['<PAD>']) for char in text]\n        encoded = pad_sequences([encoded], maxlen=self.max_length, padding='post')[0]\n        return to_categorical(encoded, num_classes=self.vocab_size)\n    \n    def decode_prediction(self, prediction):\n        \"\"\"Decode model prediction to text\"\"\"\n        predicted_indices = np.argmax(prediction, axis=-1)\n        decoded_text = ''.join([self.idx_to_char[idx] for idx in predicted_indices])\n        \n        # Remove padding and special tokens\n        decoded_text = decoded_text.replace('<PAD>', '').replace('<START>', '').replace('<END>', '')\n        \n        return decoded_text.strip()\n    \n    def train(self, train_images, train_labels, validation_split=0.2, epochs=50, batch_size=32):\n        \"\"\"Train the model\"\"\"\n        \n        # Split data\n        X_train, X_val, y_train, y_val = train_test_split(\n            train_images, train_labels, test_size=validation_split, random_state=42\n        )\n        \n        # Callbacks\n        callbacks = [\n            tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True),\n            tf.keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=5),\n            tf.keras.callbacks.ModelCheckpoint('tamil_handwriting_best.h5', save_best_only=True)\n        ]\n        \n        # Train model\n        history = self.model.fit(\n            X_train, y_train,\n            validation_data=(X_val, y_val),\n            epochs=epochs,\n            batch_size=batch_size,\n            callbacks=callbacks,\n            verbose=1\n        )\n        \n        return history\n    \n    def predict(self, image):\n        \"\"\"Predict text from image\"\"\"\n        if len(image.shape) == 3:\n            image = np.expand_dims(image, axis=0)\n        \n        prediction = self.model.predict(image)\n        decoded_text = self.decode_prediction(prediction[0])\n        \n        # Calculate confidence\n        confidence = np.mean(np.max(prediction[0], axis=-1))\n        \n        return decoded_text, confidence\n\n# Data preparation functions\ndef prepare_tamil_dataset(data_path):\n    \"\"\"\n    Prepare Tamil handwriting dataset\n    Expected structure:\n    data_path/\n    ├── images/\n    │   ├── image1.jpg\n    │   ├── image2.jpg\n    │   └── ...\n    └── labels.csv (columns: filename, text)\n    \"\"\"\n    \n    import os\n    import pandas as pd\n    \n    # Load labels\n    labels_df = pd.read_csv(os.path.join(data_path, 'labels.csv'))\n    \n    images = []\n    labels = []\n    \n    recognizer = TamilHandwritingRecognizer()\n    \n    for _, row in labels_df.iterrows():\n        image_path = os.path.join(data_path, 'images', row['filename'])\n        \n        if os.path.exists(image_path):\n            # Preprocess image\n            img = recognizer.preprocess_image(image_path)\n            images.append(img)\n            \n            # Encode label\n            encoded_label = recognizer.encode_text(row['text'])\n            labels.append(encoded_label)\n    \n    return np.array(images), np.array(labels)\n\n# Training script\nif __name__ == \"__main__\":\n    # Initialize model\n    recognizer = TamilHandwritingRecognizer()\n    model = recognizer.build_model()\n    \n    print(\"Model Summary:\")\n    model.summary()\n    \n    # Load and prepare data\n    # Download Tamil handwriting dataset from:\n    # https://www.kaggle.com/datasets/tamil-handwriting-recognition\n    # Or create custom dataset\n    \n    data_path = \"path/to/tamil_handwriting_dataset\"\n    # X_train, y_train = prepare_tamil_dataset(data_path)\n    \n    # Train model\n    # history = recognizer.train(X_train, y_train, epochs=100)\n    \n    # Save model\n    # model.save('tamil_handwriting_model.h5')\n    \n    print(\"Tamil Handwriting Recognition Model Ready!\")","metadata":{"_uuid":"43109813-e937-4906-b588-51680b9e8fa9","_cell_guid":"ea0a5c45-2755-4de1-980c-d01c7140a247","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null}]}