{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad28980a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow-addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9554440",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "def augment_image(img):\n",
    "    \"\"\"Apply random augmentation: rotation, shift, zoom, brightness, flips\"\"\"\n",
    "    img = tf.image.random_brightness(img, max_delta=0.2)\n",
    "    img = tf.image.random_contrast(img, lower=0.8, upper=1.2)\n",
    "    img = tf.image.random_flip_left_right(img)\n",
    "    img = tf.image.random_flip_up_down(img)\n",
    "    # Random rotation\n",
    "    angle = random.uniform(-0.15, 0.15)  # radians\n",
    "    img = tfa.image.rotate(img, angle)\n",
    "    return img\n",
    "\n",
    "def prepare_tamil_dataset_kaggle(data_path, recognizer, augment=False):\n",
    "    \"\"\"\n",
    "    Prepare Tamil handwriting dataset from Kaggle structure\n",
    "    data_path/\n",
    "        train.csv (columns: ImageId, Class Label)\n",
    "        Train-Kaggle/Train-Kaggle/ (images)\n",
    "    \"\"\"\n",
    "    train_csv = os.path.join(data_path, \"train.csv\")\n",
    "    img_dir = os.path.join(data_path, \"Train-Kaggle\", \"Train-Kaggle\")\n",
    "    df = pd.read_csv(train_csv)\n",
    "\n",
    "    images = []\n",
    "    labels = []\n",
    "    skipped = 0\n",
    "    for idx, row in df.iterrows():\n",
    "        img_path = os.path.join(img_dir, row['ImageId'])\n",
    "        label_idx = row['Class Label']\n",
    "        # Data cleaning: skip if file missing or label out of range\n",
    "        if not os.path.exists(img_path):\n",
    "            skipped += 1\n",
    "            continue\n",
    "        if not (0 <= label_idx < len(recognizer.tamil_chars)):\n",
    "            skipped += 1\n",
    "            continue\n",
    "        try:\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "            if img is None:\n",
    "                skipped += 1\n",
    "                continue\n",
    "            img = cv2.resize(img, (recognizer.img_width, recognizer.img_height))\n",
    "            img = img.astype(np.float32) / 255.0\n",
    "            img = np.expand_dims(img, axis=-1)\n",
    "            if augment:\n",
    "                img = augment_image(img)\n",
    "            images.append(img)\n",
    "            # One-hot encode label\n",
    "            label = recognizer.char_to_idx[recognizer.tamil_chars[label_idx]]\n",
    "            label = tf.keras.utils.to_categorical(label, num_classes=recognizer.vocab_size)\n",
    "            labels.append(label)\n",
    "        except Exception:\n",
    "            skipped += 1\n",
    "            continue\n",
    "    print(f\"Loaded {len(images)} samples, skipped {skipped} due to errors.\")\n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2984d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "def evaluate_character_level(model, X, y_true, recognizer):\n",
    "    \"\"\"Evaluate model at character level (accuracy, confusion matrix)\"\"\"\n",
    "    y_pred = model.predict(X)\n",
    "    y_pred_indices = np.argmax(y_pred, axis=-1)\n",
    "    y_true_indices = np.argmax(y_true, axis=-1)\n",
    "    acc = accuracy_score(y_true_indices, y_pred_indices)\n",
    "    cm = confusion_matrix(y_true_indices, y_pred_indices)\n",
    "    print(f\"Character-level accuracy: {acc:.4f}\")\n",
    "    return acc, cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TamilHandwritingRecognizer:\n",
    "    def __init__(self, img_height=64, img_width=256, max_length=32):\n",
    "        self.img_height = img_height\n",
    "        self.img_width = img_width\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        # Tamil character set (simplified - expand as needed)\n",
    "        self.tamil_chars = [\n",
    "            'அ', 'ஆ', 'இ', 'ஈ', 'உ', 'ஊ', 'எ', 'ஏ', 'ஐ', 'ஒ', 'ஓ', 'ஔ',\n",
    "            'க', 'ங', 'ச', 'ஞ', 'ட', 'ண', 'த', 'ந', 'ப', 'ம', 'ய', 'ர', 'ல', 'வ', 'ழ', 'ள', 'ற', 'ன',\n",
    "            'ா', 'ி', 'ீ', 'ு', 'ூ', 'ெ', 'ே', 'ை', 'ொ', 'ோ', 'ௌ', '்',\n",
    "            ' ', '<PAD>', '<START>', '<END>'\n",
    "        ]\n",
    "        \n",
    "        self.char_to_idx = {char: idx for idx, char in enumerate(self.tamil_chars)}\n",
    "        self.idx_to_char = {idx: char for idx, char in enumerate(self.tamil_chars)}\n",
    "        self.vocab_size = len(self.tamil_chars)\n",
    "        \n",
    "        self.model = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def build_model(self):\n",
    "        \"\"\"Build CNN + LSTM model for handwriting recognition\"\"\"\n",
    "        \n",
    "        # Input layer\n",
    "        input_img = layers.Input(shape=(self.img_height, self.img_width, 1), name='image_input')\n",
    "        \n",
    "        # CNN Feature Extraction\n",
    "        x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
    "        x = layers.MaxPooling2D((2, 2))(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        \n",
    "        x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "        x = layers.MaxPooling2D((2, 2))(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        \n",
    "        x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "        x = layers.MaxPooling2D((2, 2))(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        \n",
    "        x = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
    "        x = layers.MaxPooling2D((2, 2))(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        \n",
    "        # Reshape for RNN\n",
    "        new_shape = ((self.img_width // 16), (self.img_height // 16) * 256)\n",
    "        x = layers.Reshape(target_shape=new_shape)(x)\n",
    "        x = layers.Dense(64, activation='relu')(x)\n",
    "        \n",
    "        # RNN layers\n",
    "        x = layers.Bidirectional(layers.LSTM(128, return_sequences=True, dropout=0.25))(x)\n",
    "        x = layers.Bidirectional(layers.LSTM(64, return_sequences=True, dropout=0.25))(x)\n",
    "        \n",
    "        # Output layer\n",
    "        output = layers.Dense(self.vocab_size, activation='softmax', name='output')(x)\n",
    "        \n",
    "        # Create model\n",
    "        self.model = models.Model(inputs=input_img, outputs=output)\n",
    "        \n",
    "        # Compile model\n",
    "        self.model.compile(\n",
    "            optimizer='adam',\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        \n",
    "        return self.model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def preprocess_image(self, image_path):\n",
    "        \"\"\"Preprocess image for model input\"\"\"\n",
    "        img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        # Resize image\n",
    "        img = cv2.resize(img, (self.img_width, self.img_height))\n",
    "        \n",
    "        # Normalize\n",
    "        img = img.astype(np.float32) / 255.0\n",
    "        \n",
    "        # Add channel dimension\n",
    "        img = np.expand_dims(img, axis=-1)\n",
    "        \n",
    "        return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def encode_text(self, text):\n",
    "        \"\"\"Encode text to sequence of indices\"\"\"\n",
    "        encoded = [self.char_to_idx.get(char, self.char_to_idx['<PAD>']) for char in text]\n",
    "        encoded = pad_sequences([encoded], maxlen=self.max_length, padding='post')[0]\n",
    "        return to_categorical(encoded, num_classes=self.vocab_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def decode_prediction(self, prediction):\n",
    "        \"\"\"Decode model prediction to text\"\"\"\n",
    "        predicted_indices = np.argmax(prediction, axis=-1)\n",
    "        decoded_text = ''.join([self.idx_to_char[idx] for idx in predicted_indices])\n",
    "        \n",
    "        # Remove padding and special tokens\n",
    "        decoded_text = decoded_text.replace('<PAD>', '').replace('<START>', '').replace('<END>', '')\n",
    "        \n",
    "        return decoded_text.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def train(self, train_images, train_labels, validation_split=0.2, epochs=50, batch_size=32):\n",
    "        \"\"\"Train the model\"\"\"\n",
    "        \n",
    "        # Split data\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            train_images, train_labels, test_size=validation_split, random_state=42\n",
    "        )\n",
    "        \n",
    "        # Callbacks\n",
    "        callbacks = [\n",
    "            tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True),\n",
    "            tf.keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=5),\n",
    "            tf.keras.callbacks.ModelCheckpoint('tamil_handwriting_best.h5', save_best_only=True)\n",
    "        ]\n",
    "        \n",
    "        # Train model\n",
    "        history = self.model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_val, y_val),\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            callbacks=callbacks,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def predict(self, image):\n",
    "        \"\"\"Predict text from image\"\"\"\n",
    "        if len(image.shape) == 3:\n",
    "            image = np.expand_dims(image, axis=0)\n",
    "        \n",
    "        prediction = self.model.predict(image)\n",
    "        decoded_text = self.decode_prediction(prediction[0])\n",
    "        \n",
    "        # Calculate confidence\n",
    "        confidence = np.mean(np.max(prediction[0], axis=-1))\n",
    "        \n",
    "        return decoded_text, confidence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preparation functions\n",
    "def prepare_tamil_dataset(data_path):\n",
    "    \"\"\"\n",
    "    Prepare Tamil handwriting dataset\n",
    "    Expected structure:\n",
    "    data_path/\n",
    "    └─ images/\n",
    "        └─ image1.jpg\n",
    "        └─ image2.jpg\n",
    "        └─ ...\n",
    "    └─ labels.csv (columns: filename, text)\n",
    "    \"\"\"\n",
    "    \n",
    "    import os\n",
    "    import pandas as pd\n",
    "    \n",
    "    # Load labels\n",
    "    labels_df = pd.read_csv(os.path.join(data_path, 'labels.csv'))\n",
    "    \n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    recognizer = TamilHandwritingRecognizer()\n",
    "    \n",
    "    for _, row in labels_df.iterrows():\n",
    "        image_path = os.path.join(data_path, 'images', row['filename'])\n",
    "        \n",
    "        if os.path.exists(image_path):\n",
    "            # Preprocess image\n",
    "            img = recognizer.preprocess_image(image_path)\n",
    "            images.append(img)\n",
    "            \n",
    "            # Encode label\n",
    "            encoded_label = recognizer.encode_text(row['text'])\n",
    "            labels.append(encoded_label)\n",
    "    \n",
    "    return np.array(images), np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training script\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize model\n",
    "    recognizer = TamilHandwritingRecognizer()\n",
    "    model = recognizer.build_model()\n",
    "    \n",
    "    print(\"Model Summary:\")\n",
    "    model.summary()\n",
    "    \n",
    "    # Example usage in your notebook:\n",
    "    data_path = \"/kaggle/input/tamil-handwritten-character-recognition-resnet\"\n",
    "    recognizer = TamilHandwritingRecognizer()\n",
    "    X_train, y_train = prepare_tamil_dataset_kaggle(data_path, recognizer, augment=True)\n",
    "# Now you can train as before:\n",
    "# history = recognizer.train(X_train, y_train, epochs=100)\n",
    "\n",
    "    # Load and prepare data\n",
    "    # Download Tamil handwriting dataset from:\n",
    "    # https://www.kaggle.com/datasets/tamil-handwriting-recognition\n",
    "    # Or create custom dataset\n",
    "    \n",
    "    data_path = \"path/to/tamil_handwriting_dataset\"\n",
    "    # X_train, y_train = prepare_tamil_dataset(data_path)\n",
    "    \n",
    "    # Train model\n",
    "    # history = recognizer.train(X_train, y_train, epochs=100)\n",
    "    \n",
    "    # Save model\n",
    "    # model.save('tamil_handwriting_model.h5')\n",
    "    \n",
    "    print(\"Tamil Handwriting Recognition Model Ready!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
